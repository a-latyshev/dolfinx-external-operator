{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class convexLinear(torch.nn.Module):\n",
    "    \"\"\" Custom linear layer with positive weights and no bias \"\"\"\n",
    "    def __init__(self, size_in, size_out, ):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        weights = torch.Tensor(size_out, size_in)\n",
    "        self.weights = torch.nn.Parameter(weights)\n",
    "\n",
    "        # initialize weights\n",
    "        torch.nn.init.kaiming_uniform_(self.weights, a=np.sqrt(5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_times_x= torch.mm(x, torch.nn.functional.softplus(self.weights.t()))\n",
    "        return w_times_x\n",
    "\n",
    "class ICNN(torch.nn.Module):\n",
    "    def __init__(self, n_input, n_hidden, n_output, dropout):\n",
    "        super(ICNN, self).__init__()\n",
    "        # Create Module dicts for the hidden and skip-connection layers\n",
    "        self.layers = torch.nn.ModuleDict()\n",
    "        self.skip_layers = torch.nn.ModuleDict()\n",
    "        self.depth = len(n_hidden)\n",
    "        self.dropout = dropout[0]\n",
    "        self.p_dropout = dropout[1]\n",
    "\n",
    "        self.layers[str(0)] = torch.nn.Linear(n_input, n_hidden[0]).float()\n",
    "        # Create create NN with number of elements in n_hidden as depth\n",
    "        for i in range(1, self.depth):\n",
    "            self.layers[str(i)] = convexLinear(n_hidden[i-1], n_hidden[i]).float()\n",
    "            self.skip_layers[str(i)] = torch.nn.Linear(n_input, n_hidden[i]).float()\n",
    "\n",
    "        self.layers[str(self.depth)] = convexLinear(n_hidden[self.depth-1], n_output).float()\n",
    "        self.skip_layers[str(self.depth)] = convexLinear(n_input, n_output).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Get F components\n",
    "        F11 = x[:,0:1]\n",
    "        F12 = x[:,1:2]\n",
    "        F21 = x[:,2:3]\n",
    "        F22 = x[:,3:4]\n",
    "\n",
    "        # Compute right Cauchy green strain Tensor\n",
    "        C11 = F11**2 + F21**2\n",
    "        C12 = F11*F12 + F21*F22\n",
    "        C21 = F11*F12 + F21*F22\n",
    "        C22 = F12**2 + F22**2\n",
    "\n",
    "        # Compute computeStrainInvariants\n",
    "        I1 = C11 + C22 + 1.0\n",
    "        I2 = C11 + C22 - C12*C21 + C11*C22\n",
    "        I3 = C11*C22 - C12*C21\n",
    "\n",
    "        # Apply transformation to invariants\n",
    "        K1 = I1 * torch.pow(I3,-1/3) - 3.0\n",
    "        K2 = (I1 + I3 - 1) * torch.pow(I3,-2/3) - 3.0\n",
    "        J = torch.sqrt(I3)\n",
    "        K3 = (J-1)**2\n",
    "\n",
    "        # Concatenate feature\n",
    "        x_input = torch.cat((K1,K2,K3),1).float()\n",
    "\n",
    "        z = x_input.clone()\n",
    "        z = self.layers[str(0)](z)\n",
    "        for layer in range(1,self.depth):\n",
    "            skip = self.skip_layers[str(layer)](x_input)\n",
    "            z = self.layers[str(layer)](z)\n",
    "            z += skip\n",
    "            z = torch.nn.functional.softplus(z)     \n",
    "            z = 1/12.*torch.square(z)\n",
    "            if self.training:\n",
    "                if self.dropout:\n",
    "                    z = torch.nn.functional.dropout(z,p=self.p_dropout)\n",
    "        y = self.layers[str(self.depth)](z) + self.skip_layers[str(self.depth)](x_input)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/23jtbc011ldb7ngvjccl2w9sr08f79/T/ipykernel_87296/1114390409.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('ArrudaBoyce_noise=high.pth'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_input = 3\n",
    "n_output = 1\n",
    "n_hidden = [64,64,64]\n",
    "dropout = [True,0.2]\n",
    "model = ICNN(n_input=n_input,\n",
    "                n_hidden=n_hidden,\n",
    "                n_output=n_output,\n",
    "                dropout=dropout)\n",
    "\n",
    "model.load_state_dict(torch.load('ArrudaBoyce_noise=high.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Create dummy deformation gradients based on uniaxial tension\n",
    "F=torch.zeros(50,4)\n",
    "gamma=torch.linspace(0,0.5,50)\n",
    "for a in range(50):\n",
    "    F[a,0] = 1 + gamma[a]\n",
    "    F[a,1] = 0\n",
    "    F[a,2] = 0\n",
    "    F[a,3] = 1\n",
    "\n",
    "# Zero input deformation gradient + track gradients\n",
    "F_0 = torch.zeros((1,4))\n",
    "F_0[:,0] = 1\n",
    "F_0[:,3] = 1\n",
    "\n",
    "F11_0 = F_0[:,0:1]\n",
    "F12_0 = F_0[:,1:2]\n",
    "F21_0 = F_0[:,2:3]\n",
    "F22_0 = F_0[:,3:4]\n",
    "\n",
    "F11_0.requires_grad = True\n",
    "F12_0.requires_grad = True\n",
    "F21_0.requires_grad = True\n",
    "F22_0.requires_grad = True\n",
    "\n",
    "\n",
    "# Get components of F of Uniaxial tension + track gradients\n",
    "F11 = F[:,0:1]\n",
    "F12 = F[:,1:2]\n",
    "F21 = F[:,2:3]\n",
    "F22 = F[:,3:4]\n",
    "\n",
    "F11.requires_grad = True\n",
    "F12.requires_grad = True\n",
    "F21.requires_grad = True\n",
    "F22.requires_grad = True\n",
    "\n",
    "# Predict strain energy (uncorrected)\n",
    "W_NN = model(torch.cat((F11,F12,F21,F22),dim=1))\n",
    "\n",
    "# Get dW_NN/DF components\n",
    "dW_NN_dF11 = torch.autograd.grad(W_NN,F11,torch.ones(F11.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF12 = torch.autograd.grad(W_NN,F12,torch.ones(F12.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF21 = torch.autograd.grad(W_NN,F21,torch.ones(F21.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF22 = torch.autograd.grad(W_NN,F22,torch.ones(F22.shape[0],1),create_graph=True)[0]\n",
    "\n",
    "# Assemble first PK stress tensor as shape (-1,4)\n",
    "P_NN = torch.cat((dW_NN_dF11,dW_NN_dF12,dW_NN_dF21,dW_NN_dF22),dim=1)\n",
    "\n",
    "# Predict energy at zero deformation for energy correction\n",
    "W_NN_0 = model(torch.cat((F11_0,F12_0,F21_0,F22_0),dim=1))\n",
    "\n",
    "# Predict stress at zero deformation for stress correction\n",
    "dW_NN_dF11_0 = torch.autograd.grad(W_NN_0,F11_0,torch.ones(F11_0.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF12_0 = torch.autograd.grad(W_NN_0,F12_0,torch.ones(F12_0.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF21_0 = torch.autograd.grad(W_NN_0,F21_0,torch.ones(F21_0.shape[0],1),create_graph=True)[0]\n",
    "dW_NN_dF22_0 = torch.autograd.grad(W_NN_0,F22_0,torch.ones(F22_0.shape[0],1),create_graph=True)[0]\n",
    "\n",
    "P_NN_0 = torch.cat((dW_NN_dF11_0,dW_NN_dF12_0,dW_NN_dF21_0,dW_NN_dF22_0),dim=1)\n",
    "\n",
    "# Assemble stress correction term\n",
    "P_cor = torch.zeros_like(P_NN)\n",
    "\n",
    "P_cor[:,0:1] = F11*-P_NN_0[:,0:1] + F12*-P_NN_0[:,2:3]\n",
    "P_cor[:,1:2] = F11*-P_NN_0[:,1:2] + F12*-P_NN_0[:,3:4]\n",
    "P_cor[:,2:3] = F21*-P_NN_0[:,0:1] + F22*-P_NN_0[:,2:3]\n",
    "P_cor[:,3:4] = F21*-P_NN_0[:,1:2] + F22*-P_NN_0[:,3:4]\n",
    "\n",
    "# obtain final stress\n",
    "P = P_NN + P_cor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0656, 0.0000, 0.0000, 0.0125],\n",
       "        [0.1302, 0.0000, 0.0000, 0.0258],\n",
       "        [0.1940, 0.0000, 0.0000, 0.0397],\n",
       "        [0.2570, 0.0000, 0.0000, 0.0544],\n",
       "        [0.3192, 0.0000, 0.0000, 0.0698],\n",
       "        [0.3806, 0.0000, 0.0000, 0.0858],\n",
       "        [0.4412, 0.0000, 0.0000, 0.1026],\n",
       "        [0.5012, 0.0000, 0.0000, 0.1201],\n",
       "        [0.5604, 0.0000, 0.0000, 0.1382],\n",
       "        [0.6190, 0.0000, 0.0000, 0.1571],\n",
       "        [0.6769, 0.0000, 0.0000, 0.1766],\n",
       "        [0.7342, 0.0000, 0.0000, 0.1968],\n",
       "        [0.7909, 0.0000, 0.0000, 0.2177],\n",
       "        [0.8471, 0.0000, 0.0000, 0.2393],\n",
       "        [0.9026, 0.0000, 0.0000, 0.2616],\n",
       "        [0.9576, 0.0000, 0.0000, 0.2846],\n",
       "        [1.0121, 0.0000, 0.0000, 0.3082],\n",
       "        [1.0661, 0.0000, 0.0000, 0.3325],\n",
       "        [1.1196, 0.0000, 0.0000, 0.3575],\n",
       "        [1.1725, 0.0000, 0.0000, 0.3832],\n",
       "        [1.2251, 0.0000, 0.0000, 0.4095],\n",
       "        [1.2772, 0.0000, 0.0000, 0.4365],\n",
       "        [1.3288, 0.0000, 0.0000, 0.4642],\n",
       "        [1.3800, 0.0000, 0.0000, 0.4925],\n",
       "        [1.4308, 0.0000, 0.0000, 0.5215],\n",
       "        [1.4812, 0.0000, 0.0000, 0.5512],\n",
       "        [1.5313, 0.0000, 0.0000, 0.5816],\n",
       "        [1.5809, 0.0000, 0.0000, 0.6126],\n",
       "        [1.6302, 0.0000, 0.0000, 0.6442],\n",
       "        [1.6791, 0.0000, 0.0000, 0.6765],\n",
       "        [1.7277, 0.0000, 0.0000, 0.7095],\n",
       "        [1.7759, 0.0000, 0.0000, 0.7432],\n",
       "        [1.8238, 0.0000, 0.0000, 0.7775],\n",
       "        [1.8714, 0.0000, 0.0000, 0.8124],\n",
       "        [1.9187, 0.0000, 0.0000, 0.8480],\n",
       "        [1.9657, 0.0000, 0.0000, 0.8843],\n",
       "        [2.0124, 0.0000, 0.0000, 0.9212],\n",
       "        [2.0588, 0.0000, 0.0000, 0.9588],\n",
       "        [2.1050, 0.0000, 0.0000, 0.9970],\n",
       "        [2.1508, 0.0000, 0.0000, 1.0358],\n",
       "        [2.1964, 0.0000, 0.0000, 1.0753],\n",
       "        [2.2418, 0.0000, 0.0000, 1.1155],\n",
       "        [2.2869, 0.0000, 0.0000, 1.1563],\n",
       "        [2.3317, 0.0000, 0.0000, 1.1978],\n",
       "        [2.3764, 0.0000, 0.0000, 1.2398],\n",
       "        [2.4207, 0.0000, 0.0000, 1.2826],\n",
       "        [2.4649, 0.0000, 0.0000, 1.3259],\n",
       "        [2.5089, 0.0000, 0.0000, 1.3700],\n",
       "        [2.5526, 0.0000, 0.0000, 1.4146]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
