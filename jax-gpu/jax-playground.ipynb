{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "sys.setdlopenflags(os.RTLD_NOW | os.RTLD_GLOBAL)\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "from mpi4py import MPI\n",
    "from petsc4py import PETSc\n",
    "\n",
    "import jax\n",
    "import jax.lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import time\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax._src import distributed\n",
    "\n",
    "\n",
    "from dolfinx import mesh, fem\n",
    "import basix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jax.distributed.initialize() \n",
    "print(f\"Backend: {jax.default_backend()}\")\n",
    "cpus = jax.devices(\"cpu\")\n",
    "print(f\"Global devices: {cpus}\")\n",
    "print(f\"Local devices: {jax.local_devices()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "import logging\n",
    "\n",
    "def run_via_ipyparallel(function, n=8, verbose=True):\n",
    "    with ipp.Cluster(engines=\"mpi\", n=n, log_level=logging.ERROR) as cluster:\n",
    "        query = cluster[:].apply_async(function)\n",
    "        query.wait()\n",
    "        assert query.successful(), query.error\n",
    "        if verbose:\n",
    "            print(\"\".join(query.stdout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.50s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=131072)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=262144)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=393216)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    import jax\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "run_via_ipyparallel(f, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.48s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=131072)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=131072)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=262144)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=262144)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=393216)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=393216)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.01s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "Local devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import os\n",
    "    os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "\n",
    "\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    sharding = jax.sharding.NamedSharding(device_mesh, P())\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    a = jax.device_put(a, sharding)\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mpi rank == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.93s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "Local devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "\n",
      "rank = 0 Globally: #DoFs(Q):    200\n",
      "\n",
      "rank = 0 Locally: #DoFs(V_alpha):    200 scale_var (200,)\n",
      "\n",
      "Devices: eps_jax = {CpuDevice(id=0), CpuDevice(id=3), CpuDevice(id=1), CpuDevice(id=2)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_transfer():\n",
    "    import os\n",
    "    os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    from mpi4py import MPI\n",
    "    from dolfinx import mesh, fem\n",
    "    import basix\n",
    "    import jax\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    N = 10\n",
    "    domain = mesh.create_unit_square(MPI.COMM_WORLD, N, N, mesh.CellType.triangle)\n",
    "    Q_element = basix.ufl.quadrature_element(domain.topology.cell_name(), degree=1, value_shape=())\n",
    "    Q = fem.functionspace(domain, Q_element)\n",
    "    scale_var = fem.Function(Q)\n",
    "\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"rank = {MPI.COMM_WORLD.rank} Globally: #DoFs(Q): {Q.dofmap.index_map.size_global:6d}\\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Locally: #DoFs(V_alpha): {Q.dofmap.index_map.size_local:6d} scale_var {scale_var.x.array.shape}\\n\", flush=True)\n",
    "\n",
    "    device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    sharding = jax.sharding.NamedSharding(device_mesh, P('x'))\n",
    "    scale_var_values_jax = jax.device_put(scale_var.x.array, sharding)  # measure JAX device transfer time\n",
    "    print(f\"Devices: scale_var_values_jax = {scale_var_values_jax.devices()}\")\n",
    "run_via_ipyparallel(data_transfer, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 6778  # [MPa] Young modulus\n",
    "nu = 0.25  # [-] Poisson ratio\n",
    "c = 3.45  # [MPa] cohesion\n",
    "phi = 30 * np.pi / 180  # [rad] friction angle\n",
    "psi = 30 * np.pi / 180  # [rad] dilatancy angle\n",
    "theta_T = 26 * np.pi / 180  # [rad] transition angle as defined by Abbo and Sloan\n",
    "a = 0.26 * c / np.tan(phi)  # [MPa] tension cuff-off parameter\n",
    "stress_dim = 4\n",
    "\n",
    "def J3(s):\n",
    "    return s[2] * (s[0] * s[1] - s[3] * s[3] / 2.0)\n",
    "\n",
    "\n",
    "def J2(s):\n",
    "    return 0.5 * jnp.vdot(s, s)\n",
    "\n",
    "\n",
    "def theta(s):\n",
    "    J2_ = J2(s)\n",
    "    arg = -(3.0 * np.sqrt(3.0) * J3(s)) / (2.0 * jnp.sqrt(J2_ * J2_ * J2_))\n",
    "    arg = jnp.clip(arg, -1.0, 1.0)\n",
    "    theta = 1.0 / 3.0 * jnp.arcsin(arg)\n",
    "    return theta\n",
    "\n",
    "\n",
    "def sign(x):\n",
    "    return jax.lax.cond(x < 0.0, lambda x: -1, lambda x: 1, x)\n",
    "\n",
    "\n",
    "def coeff1(theta, angle):\n",
    "    return np.cos(theta_T) - (1.0 / np.sqrt(3.0)) * np.sin(angle) * np.sin(theta_T)\n",
    "\n",
    "\n",
    "def coeff2(theta, angle):\n",
    "    return sign(theta) * np.sin(theta_T) + (1.0 / np.sqrt(3.0)) * np.sin(angle) * np.cos(theta_T)\n",
    "\n",
    "\n",
    "coeff3 = 18.0 * np.cos(3.0 * theta_T) * np.cos(3.0 * theta_T) * np.cos(3.0 * theta_T)\n",
    "\n",
    "\n",
    "def C(theta, angle):\n",
    "    return (\n",
    "        -np.cos(3.0 * theta_T) * coeff1(theta, angle) - 3.0 * sign(theta) * np.sin(3.0 * theta_T) * coeff2(theta, angle)\n",
    "    ) / coeff3\n",
    "\n",
    "def B(theta, angle):\n",
    "    return (\n",
    "        sign(theta) * np.sin(6.0 * theta_T) * coeff1(theta, angle) - 6.0 * np.cos(6.0 * theta_T) * coeff2(theta, angle)\n",
    "    ) / coeff3\n",
    "\n",
    "\n",
    "def A(theta, angle):\n",
    "    return (\n",
    "        -(1.0 / np.sqrt(3.0)) * np.sin(angle) * sign(theta) * np.sin(theta_T)\n",
    "        - B(theta, angle) * sign(theta) * np.sin(3 * theta_T)\n",
    "        - C(theta, angle) * np.sin(3.0 * theta_T) * np.sin(3.0 * theta_T)\n",
    "        + np.cos(theta_T)\n",
    "    )\n",
    "\n",
    "\n",
    "def K(theta, angle):\n",
    "    def K_false(theta):\n",
    "        return jnp.cos(theta) - (1.0 / np.sqrt(3.0)) * np.sin(angle) * jnp.sin(theta)\n",
    "\n",
    "    def K_true(theta):\n",
    "        return (\n",
    "            A(theta, angle)\n",
    "            + B(theta, angle) * jnp.sin(3.0 * theta)\n",
    "            + C(theta, angle) * jnp.sin(3.0 * theta) * jnp.sin(3.0 * theta)\n",
    "        )\n",
    "\n",
    "    return jax.lax.cond(jnp.abs(theta) > theta_T, K_true, K_false, theta)\n",
    "\n",
    "def a_g(angle):\n",
    "    return a * np.tan(phi) / np.tan(angle)\n",
    "\n",
    "dev = np.array(\n",
    "    [\n",
    "        [2.0 / 3.0, -1.0 / 3.0, -1.0 / 3.0, 0.0],\n",
    "        [-1.0 / 3.0, 2.0 / 3.0, -1.0 / 3.0, 0.0],\n",
    "        [-1.0 / 3.0, -1.0 / 3.0, 2.0 / 3.0, 0.0],\n",
    "        [0.0, 0.0, 0.0, 1.0],\n",
    "    ],\n",
    "    dtype=PETSc.ScalarType,\n",
    ")\n",
    "tr = np.array([1.0, 1.0, 1.0, 0.0], dtype=PETSc.ScalarType)\n",
    "\n",
    "\n",
    "def surface(sigma_local, angle):\n",
    "    s = dev @ sigma_local\n",
    "    I1 = tr @ sigma_local\n",
    "    theta_ = theta(s)\n",
    "    return (\n",
    "        (I1 / 3.0 * np.sin(angle))\n",
    "        + jnp.sqrt(\n",
    "            J2(s) * K(theta_, angle) * K(theta_, angle) + a_g(angle) * a_g(angle) * np.sin(angle) * np.sin(angle)\n",
    "        )\n",
    "        - c * np.cos(angle)\n",
    "    )\n",
    "\n",
    "def f(sigma_local):\n",
    "    return surface(sigma_local, phi)\n",
    "\n",
    "def g(sigma_local):\n",
    "    return surface(sigma_local, psi)\n",
    "\n",
    "dgdsigma = jax.jacfwd(g)\n",
    "\n",
    "lmbda = E * nu / ((1.0 + nu) * (1.0 - 2.0 * nu))\n",
    "mu = E / (2.0 * (1.0 + nu))\n",
    "C_elas = np.array(\n",
    "    [\n",
    "        [lmbda + 2 * mu, lmbda, lmbda, 0],\n",
    "        [lmbda, lmbda + 2 * mu, lmbda, 0],\n",
    "        [lmbda, lmbda, lmbda + 2 * mu, 0],\n",
    "        [0, 0, 0, 2 * mu],\n",
    "    ],\n",
    "    dtype=PETSc.ScalarType,\n",
    ")\n",
    "S_elas = np.linalg.inv(C_elas)\n",
    "ZERO_VECTOR = np.zeros(stress_dim, dtype=PETSc.ScalarType)\n",
    "\n",
    "def deps_p(sigma_local, dlambda, deps_local, sigma_n_local):\n",
    "    sigma_elas_local = sigma_n_local + C_elas @ deps_local\n",
    "    yielding = f(sigma_elas_local)\n",
    "\n",
    "    def deps_p_elastic(sigma_local, dlambda):\n",
    "        return ZERO_VECTOR\n",
    "\n",
    "    def deps_p_plastic(sigma_local, dlambda):\n",
    "        return dlambda * dgdsigma(sigma_local)\n",
    "\n",
    "    return jax.lax.cond(yielding <= 0.0, deps_p_elastic, deps_p_plastic, sigma_local, dlambda)\n",
    "\n",
    "\n",
    "def r_g(sigma_local, dlambda, deps_local, sigma_n_local):\n",
    "    deps_p_local = deps_p(sigma_local, dlambda, deps_local, sigma_n_local)\n",
    "    return sigma_local - sigma_n_local - C_elas @ (deps_local - deps_p_local)\n",
    "\n",
    "\n",
    "def r_f(sigma_local, dlambda, deps_local, sigma_n_local):\n",
    "    sigma_elas_local = sigma_n_local + C_elas @ deps_local\n",
    "    yielding = f(sigma_elas_local)\n",
    "\n",
    "    def r_f_elastic(sigma_local, dlambda):\n",
    "        return dlambda\n",
    "\n",
    "    def r_f_plastic(sigma_local, dlambda):\n",
    "        return f(sigma_local)\n",
    "\n",
    "    return jax.lax.cond(yielding <= 0.0, r_f_elastic, r_f_plastic, sigma_local, dlambda)\n",
    "\n",
    "\n",
    "def r(y_local, deps_local, sigma_n_local):\n",
    "    sigma_local = y_local[:stress_dim]\n",
    "    dlambda_local = y_local[-1]\n",
    "\n",
    "    res_g = r_g(sigma_local, dlambda_local, deps_local, sigma_n_local)\n",
    "    res_f = r_f(sigma_local, dlambda_local, deps_local, sigma_n_local)\n",
    "\n",
    "    res = jnp.c_[\"0,1,-1\", res_g, res_f]  # concatenates an array and a scalar\n",
    "    return res\n",
    "\n",
    "drdy = jax.jacfwd(r)\n",
    "\n",
    "Nitermax, tol = 200, 1e-10\n",
    "\n",
    "ZERO_SCALAR = np.array([0.0])\n",
    "\n",
    "\n",
    "def return_mapping(deps_local, sigma_n_local):\n",
    "    \"\"\"Performs the return-mapping procedure.\n",
    "\n",
    "    It solves elastoplastic constitutive equations numerically by applying the\n",
    "    Newton method in a single Gauss point. The Newton loop is implement via\n",
    "    `jax.lax.while_loop`.\n",
    "\n",
    "    The function returns `sigma_local` two times to reuse its values after\n",
    "    differentiation, i.e. as once we apply\n",
    "    `jax.jacfwd(return_mapping, has_aux=True)` the ouput function will\n",
    "    have an output of\n",
    "    `(C_tang_local, (sigma_local, niter_total, yielding, norm_res, dlambda))`.\n",
    "\n",
    "    Returns:\n",
    "        sigma_local: The stress at the current Gauss point.\n",
    "        niter_total: The total number of iterations.\n",
    "        yielding: The value of the yield function.\n",
    "        norm_res: The norm of the residuals.\n",
    "        dlambda: The value of the plastic multiplier.\n",
    "    \"\"\"\n",
    "    niter = 0\n",
    "\n",
    "    dlambda = ZERO_SCALAR\n",
    "    sigma_local = sigma_n_local\n",
    "    y_local = jnp.concatenate([sigma_local, dlambda])\n",
    "\n",
    "    res = r(y_local, deps_local, sigma_n_local)\n",
    "    norm_res0 = jnp.linalg.norm(res)\n",
    "\n",
    "    def cond_fun(state):\n",
    "        norm_res, niter, _ = state\n",
    "        return jnp.logical_and(norm_res / norm_res0 > tol, niter < Nitermax)\n",
    "\n",
    "    def body_fun(state):\n",
    "        norm_res, niter, history = state\n",
    "\n",
    "        y_local, deps_local, sigma_n_local, res = history\n",
    "\n",
    "        j = drdy(y_local, deps_local, sigma_n_local)\n",
    "        j_inv_vp = jnp.linalg.solve(j, -res)\n",
    "        y_local = y_local + j_inv_vp\n",
    "\n",
    "        res = r(y_local, deps_local, sigma_n_local)\n",
    "        norm_res = jnp.linalg.norm(res)\n",
    "        history = y_local, deps_local, sigma_n_local, res\n",
    "\n",
    "        niter += 1\n",
    "\n",
    "        return (norm_res, niter, history)\n",
    "\n",
    "    history = (y_local, deps_local, sigma_n_local, res)\n",
    "\n",
    "    norm_res, niter_total, y_local = jax.lax.while_loop(cond_fun, body_fun, (norm_res0, niter, history))\n",
    "\n",
    "    sigma_local = y_local[0][:stress_dim]\n",
    "    dlambda = y_local[0][-1]\n",
    "    sigma_elas_local = C_elas @ deps_local\n",
    "    yielding = f(sigma_n_local + sigma_elas_local)\n",
    "\n",
    "    return sigma_local, (sigma_local, niter_total, yielding, norm_res, dlambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constitutive_response(sigma_local, sigma_n_local):\n",
    "    deps_elas = S_elas @ sigma_local\n",
    "    sigma_corrected, state = return_mapping(deps_elas, sigma_n_local)\n",
    "    yielding = state[2]\n",
    "    return sigma_corrected, yielding\n",
    "\n",
    "constitutive_response_v = jax.jit(jax.vmap(constitutive_response, in_axes=(0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_n_local = np.zeros(stress_dim, dtype=PETSc.ScalarType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49497475, -0.        , -0.49497475,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_dim = 4\n",
    "R = 0.7\n",
    "dsigma_path = np.zeros(stress_dim)\n",
    "angle = 0\n",
    "# formulas for angle \\in [-pi/6, pi/6]\n",
    "dsigma_path[0] = (R / np.sqrt(2)) * (np.cos(angle) + np.sin(angle) / np.sqrt(3))\n",
    "dsigma_path[1] = (R / np.sqrt(2)) * (-2 * np.sin(angle) / np.sqrt(3))\n",
    "dsigma_path[2] = (R / np.sqrt(2)) * (np.sin(angle) / np.sqrt(3) - np.cos(angle))\n",
    "dsigma_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([ 0.49497475,  0.        , -0.49497475,  0.        ], dtype=float64),\n",
       " Array(-2.06667052, dtype=float64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constitutive_response(dsigma_path, sigma_n_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.50s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Globally: #DoFs(Q):    200\n",
      "\n",
      "rank = 0 Locally: #DoFs(Q):     50 sigma_n_np shape (58, 4)\n",
      "rank = 0 Local devices: [CpuDevice(id=0)]\n",
      "rank = 0 sigma_corrected {CpuDevice(id=0)} yielding (58,) \n",
      "\n",
      "rank = 1 Locally: #DoFs(Q):     49 sigma_n_np shape (61, 4)\n",
      "rank = 1 Local devices: [CpuDevice(id=131072)]\n",
      "rank = 1 sigma_corrected {CpuDevice(id=131072)} yielding (61,) \n",
      "\n",
      "rank = 2 Locally: #DoFs(Q):     51 sigma_n_np shape (63, 4)\n",
      "rank = 2 Local devices: [CpuDevice(id=262144)]\n",
      "rank = 2 sigma_corrected {CpuDevice(id=262144)} yielding (63,) \n",
      "\n",
      "rank = 3 Locally: #DoFs(Q):     50 sigma_n_np shape (58, 4)\n",
      "rank = 3 Local devices: [CpuDevice(id=393216)]\n",
      "rank = 3 sigma_corrected {CpuDevice(id=393216)} yielding (58,) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def solve_constitutive_problem():\n",
    "    import os\n",
    "    # os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    from mpi4py import MPI\n",
    "    from dolfinx import mesh, fem\n",
    "    import basix\n",
    "    import jax\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "    from constitutive_model import constitutive_response\n",
    "    import numpy as np\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "\n",
    "    N = 10\n",
    "    domain = mesh.create_unit_square(MPI.COMM_WORLD, N, N, mesh.CellType.triangle)\n",
    "    stress_dim = 4\n",
    "    Q_element = basix.ufl.quadrature_element(domain.topology.cell_name(), degree=1, value_shape=(stress_dim,))\n",
    "    Q = fem.functionspace(domain, Q_element)\n",
    "    sigma_n = fem.Function(Q)\n",
    "    sigma = fem.Function(Q)\n",
    "\n",
    "    R = 0.7\n",
    "    dsigma_path = np.zeros(stress_dim)\n",
    "    angle = 0\n",
    "    # formulas for angle \\in [-pi/6, pi/6]\n",
    "    dsigma_path[0] = (R / np.sqrt(2)) * (np.cos(angle) + np.sin(angle) / np.sqrt(3))\n",
    "    dsigma_path[1] = (R / np.sqrt(2)) * (-2 * np.sin(angle) / np.sqrt(3))\n",
    "    dsigma_path[2] = (R / np.sqrt(2)) * (np.sin(angle) / np.sqrt(3) - np.cos(angle))\n",
    "    \n",
    "    # input data\n",
    "    local_size = int(sigma_n.x.array.shape[0]/stress_dim)\n",
    "    dsigma_path_np = np.tile(dsigma_path, (local_size, 1))\n",
    "    sigma_n_np = sigma_n.x.array.reshape((-1, stress_dim))\n",
    "\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"Backend: {jax.default_backend()}\")\n",
    "        print(f\"Global devices: {jax.devices()}\")\n",
    "        print(f\"Globally: #DoFs(Q): {Q.dofmap.index_map.size_global:6d}\\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Locally: #DoFs(Q): {Q.dofmap.index_map.size_local:6d} sigma_n_np shape {sigma_n_np.shape}\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Local devices: {jax.local_devices()}\", flush=True)\n",
    "\n",
    "\n",
    "    constitutive_response_v = jax.jit(jax.vmap(constitutive_response, in_axes=(0, 0)))\n",
    "    sigma_corrected, yielding = constitutive_response_v(dsigma_path_np, sigma_n_np)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} sigma_corrected {sigma_corrected.devices()} yielding max {jnp.max(yielding)=} \\n\", flush=True)\n",
    "    \n",
    "    # device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    # sharding = jax.sharding.NamedSharding(device_mesh, P('x'))\n",
    "    # scale_var_values_jax = jax.device_put(scale_var.x.array, sharding)  # measure JAX device transfer time\n",
    "    # print(f\"Devices: scale_var_values_jax = {scale_var_values_jax.devices()}\")\n",
    "run_via_ipyparallel(solve_constitutive_problem, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
