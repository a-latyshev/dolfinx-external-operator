{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "sys.setdlopenflags(os.RTLD_NOW | os.RTLD_GLOBAL)\n",
    "\n",
    "# os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'\n",
    "\n",
    "from mpi4py import MPI\n",
    "from petsc4py import PETSc\n",
    "\n",
    "import jax\n",
    "import jax.lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import time\n",
    "from timeit import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax._src import distributed\n",
    "from functools import partial\n",
    "\n",
    "from dolfinx import mesh, fem\n",
    "import basix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jax.distributed.initialize() \n",
    "print(f\"Backend: {jax.default_backend()}\")\n",
    "cpus = jax.devices(\"cpu\")\n",
    "print(f\"Global devices: {cpus}\")\n",
    "print(f\"Local devices: {jax.local_devices()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "import logging\n",
    "\n",
    "def run_via_ipyparallel(function, n=8, verbose=True):\n",
    "    with ipp.Cluster(engines=\"mpi\", n=n, log_level=logging.ERROR) as cluster:\n",
    "        query = cluster[:].apply_async(function)\n",
    "        query.wait()\n",
    "        assert query.successful(), query.error\n",
    "        if verbose:\n",
    "            print(\"\".join(query.stdout))\n",
    "    output = query.get()[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.24s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=131072)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=262144)]\n",
      "\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=393216)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def f():\n",
    "    import jax\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "run_via_ipyparallel(f, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.49s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.48s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=0)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=131072)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=131072)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=262144)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=262144)}\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=131072), CpuDevice(id=262144), CpuDevice(id=393216)]\n",
      "Local devices: [CpuDevice(id=393216)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=393216)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.01s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "Local devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "\n",
      "Devices: a = {CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def basic_work_with_distributed_arrays():\n",
    "    import os\n",
    "    os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "\n",
    "\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    sharding = jax.sharding.NamedSharding(device_mesh, P())\n",
    "    a = jnp.array([1.0, 2.0, 3.0])\n",
    "    a = jax.device_put(a, sharding)\n",
    "    print(f\"Devices: a = {a.devices()}\")\n",
    "run_via_ipyparallel(basic_work_with_distributed_arrays, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mpi rank == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.93s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "Local devices: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3)]\n",
      "\n",
      "rank = 0 Globally: #DoFs(Q):    200\n",
      "\n",
      "rank = 0 Locally: #DoFs(V_alpha):    200 scale_var (200,)\n",
      "\n",
      "Devices: eps_jax = {CpuDevice(id=0), CpuDevice(id=3), CpuDevice(id=1), CpuDevice(id=2)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def data_transfer():\n",
    "    import os\n",
    "    os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    from mpi4py import MPI\n",
    "    from dolfinx import mesh, fem\n",
    "    import basix\n",
    "    import jax\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "    print(f\"Backend: {jax.default_backend()}\")\n",
    "    print(f\"Global devices: {jax.devices()}\")\n",
    "    print(f\"Local devices: {jax.local_devices()}\\n\")\n",
    "\n",
    "    N = 10\n",
    "    domain = mesh.create_unit_square(MPI.COMM_WORLD, N, N, mesh.CellType.triangle)\n",
    "    Q_element = basix.ufl.quadrature_element(domain.topology.cell_name(), degree=1, value_shape=())\n",
    "    Q = fem.functionspace(domain, Q_element)\n",
    "    scale_var = fem.Function(Q)\n",
    "\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"rank = {MPI.COMM_WORLD.rank} Globally: #DoFs(Q): {Q.dofmap.index_map.size_global:6d}\\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Locally: #DoFs(V_alpha): {Q.dofmap.index_map.size_local:6d} scale_var {scale_var.x.array.shape}\\n\", flush=True)\n",
    "\n",
    "    device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    sharding = jax.sharding.NamedSharding(device_mesh, P('x'))\n",
    "    scale_var_values_jax = jax.device_put(scale_var.x.array, sharding)  # measure JAX device transfer time\n",
    "    print(f\"Devices: scale_var_values_jax = {scale_var_values_jax.devices()}\")\n",
    "run_via_ipyparallel(data_transfer, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constitutive_response(sigma_local, sigma_n_local):\n",
    "    deps_elas = S_elas @ sigma_local\n",
    "    sigma_corrected, state = return_mapping(deps_elas, sigma_n_local)\n",
    "    yielding = state[2]\n",
    "    return sigma_corrected, (sigma_corrected, yielding)\n",
    "\n",
    "constitutive_response_v = jax.jit(jax.vmap(constitutive_response, in_axes=(0, 0)))\n",
    "dconstitutive_response = jax.jacfwd(constitutive_response, has_aux=True)\n",
    "dconstitutive_response_v = jax.jit(jax.vmap(dconstitutive_response, in_axes=(0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stress_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sigma_n_local \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[43mstress_dim\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mPETSc\u001b[38;5;241m.\u001b[39mScalarType)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stress_dim' is not defined"
     ]
    }
   ],
   "source": [
    "sigma_n_local = np.zeros(stress_dim, dtype=PETSc.ScalarType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.49497475, -0.        , -0.49497475,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress_dim = 4\n",
    "R = 0.7\n",
    "dsigma_path = np.zeros(stress_dim)\n",
    "angle = 0\n",
    "# formulas for angle \\in [-pi/6, pi/6]\n",
    "dsigma_path[0] = (R / np.sqrt(2)) * (np.cos(angle) + np.sin(angle) / np.sqrt(3))\n",
    "dsigma_path[1] = (R / np.sqrt(2)) * (-2 * np.sin(angle) / np.sqrt(3))\n",
    "dsigma_path[2] = (R / np.sqrt(2)) * (np.sin(angle) / np.sqrt(3) - np.cos(angle))\n",
    "dsigma_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def solve_standard_problem(N):\n",
    "    import os\n",
    "    # os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    from mpi4py import MPI\n",
    "    from dolfinx import mesh, fem, common\n",
    "    import basix\n",
    "    import jax\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    import jax.numpy as jnp\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "    from constitutive_model import constitutive_response\n",
    "    import numpy as np\n",
    "\n",
    "    domain = mesh.create_unit_square(MPI.COMM_WORLD, N, N, mesh.CellType.triangle)\n",
    "    stress_dim = 4\n",
    "    Q_element = basix.ufl.quadrature_element(domain.topology.cell_name(), degree=1, value_shape=(stress_dim,))\n",
    "    Q = fem.functionspace(domain, Q_element)\n",
    "    sigma_n = fem.Function(Q)\n",
    "    sigma = fem.Function(Q)\n",
    "    sigma_n_np = sigma_n.x.array.reshape((-1, stress_dim))\n",
    "\n",
    "    local_size = int(sigma_n.x.array.shape[0]/stress_dim)\n",
    "    dsigma_path_np = np.zeros((local_size, stress_dim))\n",
    "    R = 0.1\n",
    "    angle = 0\n",
    "    # formulas for angle \\in [-pi/6, pi/6]\n",
    "    for i in range(local_size):\n",
    "        angle = np.random.uniform(-np.pi/6, np.pi/6)\n",
    "        dsigma_path_np[i,0] = (R / np.sqrt(2)) * (np.cos(angle) + np.sin(angle) / np.sqrt(3))\n",
    "        dsigma_path_np[i,1] = (R / np.sqrt(2)) * (-2 * np.sin(angle) / np.sqrt(3))\n",
    "        dsigma_path_np[i,2] = (R / np.sqrt(2)) * (np.sin(angle) / np.sqrt(3) - np.cos(angle))\n",
    "    # input data\n",
    "\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"Backend: {jax.default_backend()}\")\n",
    "        print(f\"Global devices: {jax.devices()}\")\n",
    "        print(f\"Globally: #DoFs(Q): {Q.dofmap.index_map.size_global:6d}\\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Locally: #DoFs(Q): {Q.dofmap.index_map.size_local:6d} shape(sigma_n_np): {sigma_n_np.shape}\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Local devices: {jax.local_devices()}\", flush=True)\n",
    "\n",
    "    timer = common.Timer(\"Total_timer\")\n",
    "    dconstitutive_response = jax.jacfwd(constitutive_response, has_aux=True)\n",
    "    dconstitutive_response_v = jax.jit(jax.vmap(dconstitutive_response, in_axes=(0, 0)))\n",
    "    timer.start()\n",
    "    N_loads = 100  # number of loadings or paths\n",
    "    for i in range(N_loads):\n",
    "        _, (sigma_corrected, yielding) = dconstitutive_response_v(dsigma_path_np, sigma_n_np)\n",
    "        sigma_n_np[:] = sigma_corrected\n",
    "        if MPI.COMM_WORLD.rank == 0:\n",
    "            print(f\"rank = {MPI.COMM_WORLD.rank} yielding max: {jnp.max(yielding)}\")\n",
    "    timer.stop()\n",
    "    total_time = MPI.COMM_WORLD.allreduce(timer.elapsed()[0], op=MPI.MAX)\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"rank = {MPI.COMM_WORLD.rank} Total time: {total_time} \\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} sigma_corrected is on: {sigma_corrected.devices()}\", flush=True)\n",
    "\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.25s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Globally: #DoFs(Q):    200\n",
      "\n",
      "rank = 0 Locally: #DoFs(Q):     50 shape(sigma_n_np): (58, 4)\n",
      "rank = 0 Local devices: [CpuDevice(id=0)]\n",
      "rank = 0 yielding max: -2.207484232215931\n",
      "rank = 0 yielding max: -2.197140185666778\n",
      "rank = 0 yielding max: -2.18019448018146\n",
      "rank = 0 yielding max: -2.1570510075898444\n",
      "rank = 0 yielding max: -2.1282102327968544\n",
      "rank = 0 yielding max: -2.0942236459700188\n",
      "rank = 0 yielding max: -2.0556539426208116\n",
      "rank = 0 yielding max: -2.0130450206043164\n",
      "rank = 0 yielding max: -1.9669025121528019\n",
      "rank = 0 yielding max: -1.9176834206025226\n",
      "rank = 0 yielding max: -1.8657925587242774\n",
      "rank = 0 yielding max: -1.8115834866466611\n",
      "rank = 0 yielding max: -1.7553620705434334\n",
      "rank = 0 yielding max: -1.697391311710658\n",
      "rank = 0 yielding max: -1.6378965666893268\n",
      "rank = 0 yielding max: -1.5770706373821117\n",
      "rank = 0 yielding max: -1.5150784565297208\n",
      "rank = 0 yielding max: -1.4520612507586752\n",
      "rank = 0 yielding max: -1.388140156308846\n",
      "rank = 0 yielding max: -1.323419313132397\n",
      "rank = 0 yielding max: -1.257988487261562\n",
      "rank = 0 yielding max: -1.1919252799947648\n",
      "rank = 0 yielding max: -1.125296982496628\n",
      "rank = 0 yielding max: -1.0581621301079156\n",
      "rank = 0 yielding max: -0.9905718045178373\n",
      "rank = 0 yielding max: -0.922570725361032\n",
      "rank = 0 yielding max: -0.8541981664936551\n",
      "rank = 0 yielding max: -0.7854887265144863\n",
      "rank = 0 yielding max: -0.7164729781448305\n",
      "rank = 0 yielding max: -0.6471780168646912\n",
      "rank = 0 yielding max: -0.5776279256645225\n",
      "rank = 0 yielding max: -0.5078441698308569\n",
      "rank = 0 yielding max: -0.437845933254446\n",
      "rank = 0 yielding max: -0.36765040574997876\n",
      "rank = 0 yielding max: -0.29727302923435195\n",
      "rank = 0 yielding max: -0.2267277092631197\n",
      "rank = 0 yielding max: -0.1560269973193047\n",
      "rank = 0 yielding max: -0.08518224834108379\n",
      "rank = 0 yielding max: -0.01420375722875944\n",
      "rank = 0 yielding max: 0.05689912254288476\n",
      "rank = 0 yielding max: 0.07115410573562908\n",
      "rank = 0 yielding max: 0.07118771252454348\n",
      "rank = 0 yielding max: 0.07122061981863803\n",
      "rank = 0 yielding max: 0.07125284719715985\n",
      "rank = 0 yielding max: 0.07128441355061677\n",
      "rank = 0 yielding max: 0.07131533710823668\n",
      "rank = 0 yielding max: 0.07134563546595052\n",
      "rank = 0 yielding max: 0.07137532561298032\n",
      "rank = 0 yielding max: 0.07140442395711899\n",
      "rank = 0 yielding max: 0.07143294634876574\n",
      "rank = 0 yielding max: 0.07146090810381223\n",
      "rank = 0 yielding max: 0.0714883240254025\n",
      "rank = 0 yielding max: 0.07151520842467729\n",
      "rank = 0 yielding max: 0.07154157514051551\n",
      "rank = 0 yielding max: 0.07156743755835926\n",
      "rank = 0 yielding max: 0.0715928086281421\n",
      "rank = 0 yielding max: 0.07161770088140917\n",
      "rank = 0 yielding max: 0.07164212644762591\n",
      "rank = 0 yielding max: 0.07166609706975313\n",
      "rank = 0 yielding max: 0.07168962411911162\n",
      "rank = 0 yielding max: 0.07171271860957606\n",
      "rank = 0 yielding max: 0.07173539121113182\n",
      "rank = 0 yielding max: 0.07175765226283515\n",
      "rank = 0 yielding max: 0.07177951178519226\n",
      "rank = 0 yielding max: 0.0718009794919987\n",
      "rank = 0 yielding max: 0.07182206480166808\n",
      "rank = 0 yielding max: 0.07184277684805984\n",
      "rank = 0 yielding max: 0.07186312449085719\n",
      "rank = 0 yielding max: 0.07188311632548094\n",
      "rank = 0 yielding max: 0.07190276069260193\n",
      "rank = 0 yielding max: 0.07192206568724613\n",
      "rank = 0 yielding max: 0.0719410391675086\n",
      "rank = 0 yielding max: 0.07195968876292502\n",
      "rank = 0 yielding max: 0.07197802188247371\n",
      "rank = 0 yielding max: 0.07199604572227392\n",
      "rank = 0 yielding max: 0.0720137672729444\n",
      "rank = 0 yielding max: 0.07203119332668528\n",
      "rank = 0 yielding max: 0.0720483304840589\n",
      "rank = 0 yielding max: 0.07206518516051119\n",
      "rank = 0 yielding max: 0.0720817635926232\n",
      "rank = 0 yielding max: 0.07209807184412043\n",
      "rank = 0 yielding max: 0.0721141158116465\n",
      "rank = 0 yielding max: 0.07212990123030849\n",
      "rank = 0 yielding max: 0.07214543367900772\n",
      "rank = 0 yielding max: 0.0721607185855615\n",
      "rank = 0 yielding max: 0.07217576123164049\n",
      "rank = 0 yielding max: 0.07219056675749647\n",
      "rank = 0 yielding max: 0.07220514016653068\n",
      "rank = 0 yielding max: 0.07221948632967923\n",
      "rank = 0 yielding max: 0.07223360998963857\n",
      "rank = 0 yielding max: 0.0722475157649205\n",
      "rank = 0 yielding max: 0.07226120815378456\n",
      "rank = 0 yielding max: 0.07227469153799326\n",
      "rank = 0 yielding max: 0.07228797018645183\n",
      "rank = 0 yielding max: 0.07230104825870365\n",
      "rank = 0 yielding max: 0.07231392980830575\n",
      "rank = 0 yielding max: 0.07232661878607871\n",
      "rank = 0 yielding max: 0.07233911904324142\n",
      "rank = 0 yielding max: 0.07235143433442826\n",
      "rank = 0 yielding max: 0.07236356832061608\n",
      "rank = 0 Total time: 45.980000000000004 \n",
      "\n",
      "rank = 0 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 1 Locally: #DoFs(Q):     49 shape(sigma_n_np): (61, 4)\n",
      "rank = 1 Local devices: [CpuDevice(id=0)]\n",
      "rank = 1 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 2 Locally: #DoFs(Q):     51 shape(sigma_n_np): (63, 4)\n",
      "rank = 2 Local devices: [CpuDevice(id=0)]\n",
      "rank = 2 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 3 Locally: #DoFs(Q):     50 shape(sigma_n_np): (58, 4)\n",
      "rank = 3 Local devices: [CpuDevice(id=0)]\n",
      "rank = 3 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.26s/engine]\n",
      "Backend: cpu\n",
      "Global devices: [CpuDevice(id=0)]\n",
      "Globally: #DoFs(Q):  20000\n",
      "\n",
      "rank = 0 Locally: #DoFs(Q):   5026 shape(sigma_n_np): (5212, 4)\n",
      "rank = 0 Local devices: [CpuDevice(id=0)]\n",
      "rank = 0 yielding max: -2.2074842299252957\n",
      "rank = 0 yielding max: -2.1971401766241105\n",
      "rank = 0 yielding max: -2.180194460262379\n",
      "rank = 0 yielding max: -2.157050973164678\n",
      "rank = 0 yielding max: -2.1282101808122866\n",
      "rank = 0 yielding max: -2.0942235739594475\n",
      "rank = 0 yielding max: -2.05565384866205\n",
      "rank = 0 yielding max: -2.0130449032472004\n",
      "rank = 0 yielding max: -1.9669023703360458\n",
      "rank = 0 yielding max: -1.9176832535729673\n",
      "rank = 0 yielding max: -1.8657923659656541\n",
      "rank = 0 yielding max: -1.8115832678205317\n",
      "rank = 0 yielding max: -1.7553618254422565\n",
      "rank = 0 yielding max: -1.6973910402215924\n",
      "rank = 0 yielding max: -1.637896268766911\n",
      "rank = 0 yielding max: -1.577070313027968\n",
      "rank = 0 yielding max: -1.5150781057776592\n",
      "rank = 0 yielding max: -1.4520608736638736\n",
      "rank = 0 yielding max: -1.3881397529400528\n",
      "rank = 0 yielding max: -1.3234188835663685\n",
      "rank = 0 yielding max: -1.2579880315791272\n",
      "rank = 0 yielding max: -1.1919247982780772\n",
      "rank = 0 yielding max: -1.1252964748272758\n",
      "rank = 0 yielding max: -1.0581615965656515\n",
      "rank = 0 yielding max: -0.9905712451797519\n",
      "rank = 0 yielding max: -0.9225701403010458\n",
      "rank = 0 yielding max: -0.8541975557822337\n",
      "rank = 0 yielding max: -0.7854880902185184\n",
      "rank = 0 yielding max: -0.716472316327609\n",
      "rank = 0 yielding max: -0.6471773295859737\n",
      "rank = 0 yielding max: -0.5776272129806408\n",
      "rank = 0 yielding max: -0.5078434317948557\n",
      "rank = 0 yielding max: -0.4378451699162418\n",
      "rank = 0 yielding max: -0.3676496171565269\n",
      "rank = 0 yielding max: -0.29727221542981885\n",
      "rank = 0 yielding max: -0.22672687028904903\n",
      "rank = 0 yielding max: -0.15602613321478387\n",
      "rank = 0 yielding max: -0.08518135914290159\n",
      "rank = 0 yielding max: -0.014202842971557939\n",
      "rank = 0 yielding max: 0.05690006182647167\n",
      "rank = 0 yielding max: 0.07115412968227508\n",
      "rank = 0 yielding max: 0.07118773648350407\n",
      "rank = 0 yielding max: 0.07122064378949977\n",
      "rank = 0 yielding max: 0.0712528711795275\n",
      "rank = 0 yielding max: 0.07128443754410796\n",
      "rank = 0 yielding max: 0.07131536111248504\n",
      "rank = 0 yielding max: 0.07134565948060212\n",
      "rank = 0 yielding max: 0.07137534963769676\n",
      "rank = 0 yielding max: 0.07140444799157031\n",
      "rank = 0 yielding max: 0.07143297039264018\n",
      "rank = 0 yielding max: 0.0714609321568016\n",
      "rank = 0 yielding max: 0.07148834808721727\n",
      "rank = 0 yielding max: 0.07151523249503589\n",
      "rank = 0 yielding max: 0.07154159921914616\n",
      "rank = 0 yielding max: 0.07156746164499816\n",
      "rank = 0 yielding max: 0.07159283272253747\n",
      "rank = 0 yielding max: 0.0716177249833172\n",
      "rank = 0 yielding max: 0.07164215055681211\n",
      "rank = 0 yielding max: 0.07166612118599014\n",
      "rank = 0 yielding max: 0.07168964824217916\n",
      "rank = 0 yielding max: 0.07171274273926365\n",
      "rank = 0 yielding max: 0.0717354153472356\n",
      "rank = 0 yielding max: 0.07175767640515796\n",
      "rank = 0 yielding max: 0.07177953593354447\n",
      "rank = 0 yielding max: 0.07180100364619468\n",
      "rank = 0 yielding max: 0.0718220889615293\n",
      "rank = 0 yielding max: 0.07184280101341756\n",
      "rank = 0 yielding max: 0.07186314866154397\n",
      "rank = 0 yielding max: 0.0718831405013356\n",
      "rank = 0 yielding max: 0.07190278487347079\n",
      "rank = 0 yielding max: 0.07192208987297644\n",
      "rank = 0 yielding max: 0.07194106335795869\n",
      "rank = 0 yielding max: 0.07195971295795145\n",
      "rank = 0 yielding max: 0.0719780460819428\n",
      "rank = 0 yielding max: 0.0719960699260529\n",
      "rank = 0 yielding max: 0.0720137914809067\n",
      "rank = 0 yielding max: 0.07203121753870656\n",
      "rank = 0 yielding max: 0.07204835470002147\n",
      "rank = 0 yielding max: 0.07206520938029781\n",
      "rank = 0 yielding max: 0.07208178781612196\n",
      "rank = 0 yielding max: 0.0720980960712243\n",
      "rank = 0 yielding max: 0.07211414004225025\n",
      "rank = 0 yielding max: 0.07212992546430907\n",
      "rank = 0 yielding max: 0.07214545791630833\n",
      "rank = 0 yielding max: 0.07216074282606533\n",
      "rank = 0 yielding max: 0.07217578547525605\n",
      "rank = 0 yielding max: 0.07219059100413272\n",
      "rank = 0 yielding max: 0.07220516441610281\n",
      "rank = 0 yielding max: 0.07221951058210152\n",
      "rank = 0 yielding max: 0.07223363424482754\n",
      "rank = 0 yielding max: 0.07224754002279976\n",
      "rank = 0 yielding max: 0.07226123241427507\n",
      "rank = 0 yielding max: 0.07227471580102263\n",
      "rank = 0 yielding max: 0.07228799445194589\n",
      "rank = 0 yielding max: 0.07230107252659135\n",
      "rank = 0 yielding max: 0.07231395407852004\n",
      "rank = 0 yielding max: 0.0723266430585543\n",
      "rank = 0 yielding max: 0.07233914331791125\n",
      "rank = 0 yielding max: 0.07235145861123193\n",
      "rank = 0 yielding max: 0.07236359259949099\n",
      "rank = 0 Total time: 116.97000000000001 \n",
      "\n",
      "rank = 0 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 1 Locally: #DoFs(Q):   4993 shape(sigma_n_np): (5069, 4)\n",
      "rank = 1 Local devices: [CpuDevice(id=0)]\n",
      "rank = 1 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 2 Locally: #DoFs(Q):   5013 shape(sigma_n_np): (5202, 4)\n",
      "rank = 2 Local devices: [CpuDevice(id=0)]\n",
      "rank = 2 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "rank = 3 Locally: #DoFs(Q):   4968 shape(sigma_n_np): (5047, 4)\n",
      "rank = 3 Local devices: [CpuDevice(id=0)]\n",
      "rank = 3 sigma_corrected is on: {CpuDevice(id=0)}\n",
      "\n",
      "100%|██████████| 4/4 [00:09<00:00,  2.25s/engine]\n"
     ]
    }
   ],
   "source": [
    "N_list = [10, 100, 1000]\n",
    "times = np.zeros(len(N_list))\n",
    "\n",
    "for i, N in enumerate(N_list):\n",
    "    times[i] = run_via_ipyparallel(partial(solve_standard_problem, N), n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14.33,  16.98, 273.75])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_distributed_problem(N):\n",
    "    import os\n",
    "    # os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=4'\n",
    "    from mpi4py import MPI\n",
    "    from dolfinx import mesh, fem, common\n",
    "    import basix\n",
    "    import jax\n",
    "    jax.config.update(\"jax_enable_x64\", True)\n",
    "    import jax.numpy as jnp\n",
    "    from jax.sharding import PartitionSpec as P\n",
    "    from constitutive_model import constitutive_response\n",
    "    import numpy as np\n",
    "\n",
    "    jax.distributed.initialize()\n",
    "\n",
    "    domain = mesh.create_unit_square(MPI.COMM_WORLD, N, N, mesh.CellType.triangle)\n",
    "    stress_dim = 4\n",
    "    Q_element = basix.ufl.quadrature_element(domain.topology.cell_name(), degree=1, value_shape=(stress_dim,))\n",
    "    Q = fem.functionspace(domain, Q_element)\n",
    "    sigma_n = fem.Function(Q)\n",
    "    sigma = fem.Function(Q)\n",
    "\n",
    "    R = 0.1\n",
    "    dsigma_path = np.zeros(stress_dim)\n",
    "    angle = 0\n",
    "    # formulas for angle \\in [-pi/6, pi/6]\n",
    "    dsigma_path[0] = (R / np.sqrt(2)) * (np.cos(angle) + np.sin(angle) / np.sqrt(3))\n",
    "    dsigma_path[1] = (R / np.sqrt(2)) * (-2 * np.sin(angle) / np.sqrt(3))\n",
    "    dsigma_path[2] = (R / np.sqrt(2)) * (np.sin(angle) / np.sqrt(3) - np.cos(angle))\n",
    "\n",
    "    # input data\n",
    "    local_size = int(sigma_n.x.array.shape[0]/stress_dim)\n",
    "    dsigma_path_np = np.tile(dsigma_path, (local_size, 1))\n",
    "    sigma_n_np = sigma_n.x.array.reshape((-1, stress_dim))\n",
    "\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"Backend: {jax.default_backend()}\")\n",
    "        print(f\"Global devices: {jax.devices()}\")\n",
    "        print(f\"Globally: #DoFs(Q): {Q.dofmap.index_map.size_global:6d}\\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Locally: #DoFs(Q): {Q.dofmap.index_map.size_local:6d} shape(sigma_n_np): {sigma_n_np.shape}\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} Local devices: {jax.local_devices()}\", flush=True)\n",
    "\n",
    "    timer = common.Timer(\"Total_timer\")\n",
    "    dconstitutive_response = jax.jacfwd(constitutive_response, has_aux=True)\n",
    "    dconstitutive_response_v = jax.jit(jax.vmap(dconstitutive_response, in_axes=(0, 0)))\n",
    "    timer.start()\n",
    "    N_loads = 100  # number of loadings or paths\n",
    "    for i in range(N_loads):\n",
    "        _, (sigma_corrected, yielding) = dconstitutive_response_v(dsigma_path_np, sigma_n_np)\n",
    "        sigma_n_np[:] = sigma_corrected\n",
    "        print(f\"rank = {MPI.COMM_WORLD.rank} yielding max: {jnp.max(yielding)}\")\n",
    "    timer.stop()\n",
    "    total_time = MPI.COMM_WORLD.allreduce(timer.elapsed()[0], op=MPI.MAX)\n",
    "    if MPI.COMM_WORLD.rank == 0:\n",
    "        print(f\"rank = {MPI.COMM_WORLD.rank} Total time: {total_time} \\n\", flush=True)\n",
    "    print(f\"rank = {MPI.COMM_WORLD.rank} sigma_corrected is on: {sigma_corrected.devices()}\", flush=True)\n",
    "\n",
    "    # device_mesh = jax.make_mesh((4,), ('x',))\n",
    "    # sharding = jax.sharding.NamedSharding(device_mesh, P('x'))\n",
    "    # scale_var_values_jax = jax.device_put(scale_var.x.array, sharding)  # measure JAX device transfer time\n",
    "    # print(f\"Devices: scale_var_values_jax = {scale_var_values_jax.devices()}\")\n",
    "    return total_time_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:08<00:00,  2.24s/engine]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(N_list))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, N \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(N_list):\n\u001b[0;32m----> 5\u001b[0m     times[i] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_via_ipyparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolve_distributed_problem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m, in \u001b[0;36mrun_via_ipyparallel\u001b[0;34m(function, n, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ipp\u001b[38;5;241m.\u001b[39mCluster(engines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, n\u001b[38;5;241m=\u001b[39mn, log_level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mERROR) \u001b[38;5;28;01mas\u001b[39;00m cluster:\n\u001b[1;32m      6\u001b[0m     query \u001b[38;5;241m=\u001b[39m cluster[:]\u001b[38;5;241m.\u001b[39mapply_async(function)\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m query\u001b[38;5;241m.\u001b[39msuccessful(), query\u001b[38;5;241m.\u001b[39merror\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/mnt/aiongpfs/users/alatyshev/.spack/var/spack/environments/fenicsx-v09/.spack-env/view/lib/python3.11/site-packages/ipyparallel/client/asyncresult.py:490\u001b[0m, in \u001b[0;36mAsyncResult.wait\u001b[0;34m(self, timeout, return_when)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ready:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ready_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_for_output(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ready\n",
      "File \u001b[0;32m/mnt/aiongpfs/users/alatyshev/.spack/opt/spack/linux-rhel8-zen2/gcc-13.2.0/python-3.11.9-kdqfr3veqioeapej76o34ilxydsz5rvu/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/mnt/aiongpfs/users/alatyshev/.spack/opt/spack/linux-rhel8-zen2/gcc-13.2.0/python-3.11.9-kdqfr3veqioeapej76o34ilxydsz5rvu/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_list = [10, 100, 1000]\n",
    "times = np.zeros(len(N_list))\n",
    "\n",
    "for i, N in enumerate(N_list):\n",
    "    times[i] = run_via_ipyparallel(partial(solve_distributed_problem, N), n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.4 ,  6.87, 45.94])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
